{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bef06d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sanjay/anaconda3/envs/powertac_ddpg/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "sys.path.insert(1, './gym_powertac')\n",
    "\n",
    "from powertac_wm import PowerTAC_WM\n",
    "import gym\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "from ReplayBuffer import ReplayBuffer\n",
    "from ActorNetwork import ActorNetwork\n",
    "from CriticNetwork import CriticNetwork\n",
    "from OU import OU\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "891754b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_storage_path = \"ddpg_v0.0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e448c47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 1000\n",
    "GAMMA = 0.99\n",
    "TAU = 0.001     #Target Network HyperParameters\n",
    "LRA = 0.0001    #Learning rate for Actor\n",
    "LRC = 0.001     #Lerning rate for Critic\n",
    "\n",
    "'''\n",
    "Action : [\n",
    "           limitprice belongs to R\n",
    "         ] (one output nuerons)\n",
    "'''\n",
    "action_dim = 1\n",
    "\n",
    "'''\n",
    "State : [\n",
    "          Proximity (24)\n",
    "          Required_Quantity (1)\n",
    "        ] (total 25 input nuerons)\n",
    "'''\n",
    "state_dim = 25\n",
    "\n",
    "np.random.seed(1337)\n",
    "EXPLORE = 100000.0\n",
    "\n",
    "step = 0\n",
    "epsilon = 1\n",
    "\n",
    "ou = OU()       #Ornstein-Uhlenbeck Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "851e49f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(\n",
    "    device_count={'GPU': 1},\n",
    "    intra_op_parallelism_threads=1,\n",
    "    allow_soft_placement=True\n",
    ")\n",
    "\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11c3fb49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ./gym_powertac/ActorNetwork.py:16: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 25)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 400)               10400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               120300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 301       \n",
      "_________________________________________________________________\n",
      "concatenate (Concatenate)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 131,001\n",
      "Trainable params: 131,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 25)]              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 400)               10400     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               120300    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 301       \n",
      "_________________________________________________________________\n",
      "concatenate_1 (Concatenate)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 131,001\n",
      "Trainable params: 131,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/sanjay/anaconda3/envs/powertac_ddpg/lib/python3.8/site-packages/tensorflow/python/util/tf_should_use.py:247: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 400)          10400       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "action2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 300)          120300      dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 300)          600         action2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 300)          0           dense_8[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 300)          90300       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            301         dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 221,901\n",
      "Trainable params: 221,901\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 400)          10400       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "action2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 300)          120300      dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 300)          600         action2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 300)          0           dense_13[0][0]                   \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 300)          90300       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1)            301         dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 221,901\n",
      "Trainable params: 221,901\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "actor = ActorNetwork(session, state_dim, action_dim, BATCH_SIZE, TAU, LRA)\n",
    "critic = CriticNetwork(session, state_dim, action_dim, BATCH_SIZE, TAU, LRC)\n",
    "replay_buffer = pd.read_csv('replay_buffer_big.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b80c35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166987, 53)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32e48cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler_robust = preprocessing.RobustScaler(quantile_range=(15.0, 85.0))\n",
    "# robust_replay_buffer = scaler_robust.fit_transform(replay_buffer)\n",
    "\n",
    "# scaler_minmax = preprocessing.MinMaxScaler()\n",
    "# minmax_replay_buffer = scaler_minmax.fit_transform(robust_replay_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd578e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_replay_buffer = replay_buffer\n",
    "scaler_standard = preprocessing.StandardScaler()\n",
    "standard_replay_buffer[standard_replay_buffer.columns[[24, 25, 26, 51]]] = \\\n",
    "scaler_standard.fit_transform(standard_replay_buffer[standard_replay_buffer.columns[[24, 25, 26, 51]]])\n",
    "standard_replay_buffer = np.asarray(standard_replay_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4321c525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ddpg_network():\n",
    "\n",
    "    epoch_list = list()\n",
    "    loss_list = list()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        print(\"Epoch \", (epoch+1))\n",
    "        print(\"-\"*12)\n",
    "        loss = 0\n",
    "\n",
    "        #Do the batch update\n",
    "        batch = standard_replay_buffer[np.random.randint(standard_replay_buffer.shape[0], size=BATCH_SIZE), :]\n",
    "        states = batch[:, 0:25]\n",
    "        actions = batch[:, 25:26]\n",
    "        rewards = batch[:, 26:27]\n",
    "        new_states = batch[:, 27:52]\n",
    "        terminals = batch[:, 52:53]\n",
    "\n",
    "        y_t = np.zeros([BATCH_SIZE,1])\n",
    "\n",
    "#         print(\"States\", states.shape)\n",
    "#         print(\"Actions\", actions.shape)\n",
    "#         print(\"Rewards\", rewards.shape)\n",
    "#         print(\"New_States\", new_states.shape)\n",
    "\n",
    "        with session.as_default():\n",
    "            with session.graph.as_default():\n",
    "\n",
    "                target_q_values = critic.target_model.predict([new_states, actor.target_model.predict(new_states)])\n",
    "                # print(\"Target_Q_Values\", target_q_values.shape)\n",
    "\n",
    "                for k in range(BATCH_SIZE):\n",
    "                    if terminals[k] == 1:\n",
    "                        y_t[k] = rewards[k]\n",
    "                    else:\n",
    "                        y_t[k] = rewards[k] + GAMMA*target_q_values[k]\n",
    "\n",
    "                # print(\"Bellman Rewards\", y_t)\n",
    "                loss += critic.model.train_on_batch([states,actions], y_t)\n",
    "                print(\"Loss\", loss)\n",
    "                epoch_list.append(epoch)\n",
    "                loss_list.append(loss)\n",
    "                a_for_grad = actor.model.predict(states)      # This may not be required, a_for_grad should be replaced by actions ##### Check PENDING #####\n",
    "                # print(\"a_for_grad\", a_for_grad)\n",
    "                grads = critic.gradients(states, a_for_grad)       # a_for_grad is replaced by actions ##### Check PENDING #####   shape ERROR \n",
    "                # print(\"grads\", grads)\n",
    "                actor.train(states, grads)\n",
    "                actor.target_train()\n",
    "                critic.target_train()\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Training Completed in {} seconds!!!\".format(end-start))\n",
    "    return epoch_list, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f435af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_Action(states):\n",
    "\n",
    "        actions = list()\n",
    "\n",
    "        for state in states:\n",
    "\n",
    "            try:\n",
    "\n",
    "                # self.epsilon -= 1.0 / self.EXPLORE\n",
    "                # a_t = np.zeros([self.action_dim])\n",
    "                # noise_t = np.zeros([self.action_dim])\n",
    "\n",
    "                with session.as_default():\n",
    "                    with session.graph.as_default():\n",
    "\n",
    "                        a_t_original = actor.model.predict(state.reshape(1, state.shape[0]))[0].tolist()\n",
    "                        # noise_t[0] = max(self.epsilon, 0) * self.ou.function(a_t_original[0],  0.0 , 0.60, 0.30)  # decide theta, sigma and mu for limitprice\n",
    "\n",
    "                        # a_t[0] = a_t_original[0] + noise_t[0]\n",
    "                        # a_t[1] = a_t_original[1] + noise_t[1]\n",
    "\n",
    "                        # print(a_t_original)\n",
    "                        actions.append(list(a_t_original))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a380f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models():\n",
    "\n",
    "        with session.as_default():\n",
    "                with session.graph.as_default():        \n",
    "\n",
    "                    timestamp = int(datetime.datetime.now().timestamp())\n",
    "\n",
    "                    actor.model.save_weights(model_storage_path + \"/actormodel.h5\", overwrite=True)\n",
    "                    with open(model_storage_path + \"/actormodel.json\", \"w\") as outfile:\n",
    "                        json.dump(actor.model.to_json(), outfile)\n",
    "\n",
    "                    critic.model.save_weights(model_storage_path + \"/criticmodel.h5\", overwrite=True)\n",
    "                    with open(model_storage_path + \"/criticmodel.json\", \"w\") as outfile:\n",
    "                        json.dump(critic.model.to_json(), outfile)\n",
    "\n",
    "                    actor.target_model.save_weights(model_storage_path + \"/actortargetmodel.h5\", overwrite=True)\n",
    "                    with open(model_storage_path + \"/actormodeltarget.json\", \"w\") as outfile:\n",
    "                        json.dump(actor.target_model.to_json(), outfile)\n",
    "\n",
    "                    critic.target_model.save_weights(model_storage_path + \"/critictargetmodel.h5\", overwrite=True)\n",
    "                    with open(model_storage_path + \"/criticmodeltarget.json\", \"w\") as outfile:\n",
    "                        json.dump(critic.target_model.to_json(), outfile)\n",
    "\n",
    "                    print(\"Models Saved Successfully !!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c6ac581",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanjay/anaconda3/envs/powertac_ddpg/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.3111554682254791\n",
      "Epoch  2\n",
      "------------\n",
      "Loss 0.15867307782173157\n",
      "Epoch  3\n",
      "------------\n",
      "Loss 0.4277224540710449\n",
      "Epoch  4\n",
      "------------\n",
      "Loss 0.6207340359687805\n",
      "Epoch  5\n",
      "------------\n",
      "Loss 2.070405960083008\n",
      "Epoch  6\n",
      "------------\n",
      "Loss 0.2100202441215515\n",
      "Epoch  7\n",
      "------------\n",
      "Loss 0.22793734073638916\n",
      "Epoch  8\n",
      "------------\n",
      "Loss 3.386211395263672\n",
      "Epoch  9\n",
      "------------\n",
      "Loss 0.3099098205566406\n",
      "Epoch  10\n",
      "------------\n",
      "Loss 0.23517154157161713\n",
      "Epoch  11\n",
      "------------\n",
      "Loss 0.30381494760513306\n",
      "Epoch  12\n",
      "------------\n",
      "Loss 0.6238116025924683\n",
      "Epoch  13\n",
      "------------\n",
      "Loss 0.12479469925165176\n",
      "Epoch  14\n",
      "------------\n",
      "Loss 2.180464267730713\n",
      "Epoch  15\n",
      "------------\n",
      "Loss 0.3014506995677948\n",
      "Epoch  16\n",
      "------------\n",
      "Loss 0.6192029714584351\n",
      "Epoch  17\n",
      "------------\n",
      "Loss 0.4792523682117462\n",
      "Epoch  18\n",
      "------------\n",
      "Loss 0.4355328381061554\n",
      "Epoch  19\n",
      "------------\n",
      "Loss 0.23651981353759766\n",
      "Epoch  20\n",
      "------------\n",
      "Loss 0.38488292694091797\n",
      "Epoch  21\n",
      "------------\n",
      "Loss 0.2386743426322937\n",
      "Epoch  22\n",
      "------------\n",
      "Loss 0.3979825973510742\n",
      "Epoch  23\n",
      "------------\n",
      "Loss 0.14282715320587158\n",
      "Epoch  24\n",
      "------------\n",
      "Loss 0.29647204279899597\n",
      "Epoch  25\n",
      "------------\n",
      "Loss 0.15566731989383698\n",
      "Epoch  26\n",
      "------------\n",
      "Loss 0.14299653470516205\n",
      "Epoch  27\n",
      "------------\n",
      "Loss 0.35067883133888245\n",
      "Epoch  28\n",
      "------------\n",
      "Loss 0.24955004453659058\n",
      "Epoch  29\n",
      "------------\n",
      "Loss 0.5805248022079468\n",
      "Epoch  30\n",
      "------------\n",
      "Loss 0.2772710919380188\n",
      "Epoch  31\n",
      "------------\n",
      "Loss 0.09761762619018555\n",
      "Epoch  32\n",
      "------------\n",
      "Loss 0.21311379969120026\n",
      "Epoch  33\n",
      "------------\n",
      "Loss 0.2845551371574402\n",
      "Epoch  34\n",
      "------------\n",
      "Loss 0.12136391550302505\n",
      "Epoch  35\n",
      "------------\n",
      "Loss 0.37885767221450806\n",
      "Epoch  36\n",
      "------------\n",
      "Loss 0.30402565002441406\n",
      "Epoch  37\n",
      "------------\n",
      "Loss 0.271838515996933\n",
      "Epoch  38\n",
      "------------\n",
      "Loss 1.25593101978302\n",
      "Epoch  39\n",
      "------------\n",
      "Loss 1.3893576860427856\n",
      "Epoch  40\n",
      "------------\n",
      "Loss 0.200768381357193\n",
      "Epoch  41\n",
      "------------\n",
      "Loss 0.21549513936042786\n",
      "Epoch  42\n",
      "------------\n",
      "Loss 0.4293631911277771\n",
      "Epoch  43\n",
      "------------\n",
      "Loss 0.26988887786865234\n",
      "Epoch  44\n",
      "------------\n",
      "Loss 2.5685343742370605\n",
      "Epoch  45\n",
      "------------\n",
      "Loss 0.1852104365825653\n",
      "Epoch  46\n",
      "------------\n",
      "Loss 0.15239958465099335\n",
      "Epoch  47\n",
      "------------\n",
      "Loss 1.7636291980743408\n",
      "Epoch  48\n",
      "------------\n",
      "Loss 0.19765344262123108\n",
      "Epoch  49\n",
      "------------\n",
      "Loss 0.22910338640213013\n",
      "Epoch  50\n",
      "------------\n",
      "Loss 0.7165213823318481\n",
      "Epoch  51\n",
      "------------\n",
      "Loss 0.20445746183395386\n",
      "Epoch  52\n",
      "------------\n",
      "Loss 0.17129063606262207\n",
      "Epoch  53\n",
      "------------\n",
      "Loss 0.8549503087997437\n",
      "Epoch  54\n",
      "------------\n",
      "Loss 4.563322067260742\n",
      "Epoch  55\n",
      "------------\n",
      "Loss 0.4322352409362793\n",
      "Epoch  56\n",
      "------------\n",
      "Loss 0.2553905248641968\n",
      "Epoch  57\n",
      "------------\n",
      "Loss 0.4313982129096985\n",
      "Epoch  58\n",
      "------------\n",
      "Loss 0.18138986825942993\n",
      "Epoch  59\n",
      "------------\n",
      "Loss 0.24228522181510925\n",
      "Epoch  60\n",
      "------------\n",
      "Loss 0.3742954730987549\n",
      "Epoch  61\n",
      "------------\n",
      "Loss 0.12186987698078156\n",
      "Epoch  62\n",
      "------------\n",
      "Loss 0.15138009190559387\n",
      "Epoch  63\n",
      "------------\n",
      "Loss 0.7017134428024292\n",
      "Epoch  64\n",
      "------------\n",
      "Loss 0.3469800353050232\n",
      "Epoch  65\n",
      "------------\n",
      "Loss 0.32555651664733887\n",
      "Epoch  66\n",
      "------------\n",
      "Loss 1.1725765466690063\n",
      "Epoch  67\n",
      "------------\n",
      "Loss 0.8184670209884644\n",
      "Epoch  68\n",
      "------------\n",
      "Loss 0.11465897411108017\n",
      "Epoch  69\n",
      "------------\n",
      "Loss 0.3108522295951843\n",
      "Epoch  70\n",
      "------------\n",
      "Loss 0.21428626775741577\n",
      "Epoch  71\n",
      "------------\n",
      "Loss 0.2539580762386322\n",
      "Epoch  72\n",
      "------------\n",
      "Loss 1.0559805631637573\n",
      "Epoch  73\n",
      "------------\n",
      "Loss 2.7833778858184814\n",
      "Epoch  74\n",
      "------------\n",
      "Loss 4.860977649688721\n",
      "Epoch  75\n",
      "------------\n",
      "Loss 0.41274207830429077\n",
      "Epoch  76\n",
      "------------\n",
      "Loss 0.15269367396831512\n",
      "Epoch  77\n",
      "------------\n",
      "Loss 0.5088852047920227\n",
      "Epoch  78\n",
      "------------\n",
      "Loss 0.275021493434906\n",
      "Epoch  79\n",
      "------------\n",
      "Loss 2.8670966625213623\n",
      "Epoch  80\n",
      "------------\n",
      "Loss 0.3224838972091675\n",
      "Epoch  81\n",
      "------------\n",
      "Loss 0.16521793603897095\n",
      "Epoch  82\n",
      "------------\n",
      "Loss 0.3996877372264862\n",
      "Epoch  83\n",
      "------------\n",
      "Loss 0.14346757531166077\n",
      "Epoch  84\n",
      "------------\n",
      "Loss 0.23406004905700684\n",
      "Epoch  85\n",
      "------------\n",
      "Loss 0.24110350012779236\n",
      "Epoch  86\n",
      "------------\n",
      "Loss 0.30007627606391907\n",
      "Epoch  87\n",
      "------------\n",
      "Loss 0.10859810560941696\n",
      "Epoch  88\n",
      "------------\n",
      "Loss 0.44339996576309204\n",
      "Epoch  89\n",
      "------------\n",
      "Loss 0.2961525321006775\n",
      "Epoch  90\n",
      "------------\n",
      "Loss 0.16926631331443787\n",
      "Epoch  91\n",
      "------------\n",
      "Loss 0.923328161239624\n",
      "Epoch  92\n",
      "------------\n",
      "Loss 2.9544243812561035\n",
      "Epoch  93\n",
      "------------\n",
      "Loss 0.25482627749443054\n",
      "Epoch  94\n",
      "------------\n",
      "Loss 0.12767121195793152\n",
      "Epoch  95\n",
      "------------\n",
      "Loss 0.20259128510951996\n",
      "Epoch  96\n",
      "------------\n",
      "Loss 0.04071410745382309\n",
      "Epoch  97\n",
      "------------\n",
      "Loss 0.24518775939941406\n",
      "Epoch  98\n",
      "------------\n",
      "Loss 0.14514197409152985\n",
      "Epoch  99\n",
      "------------\n",
      "Loss 1.6566671133041382\n",
      "Epoch  100\n",
      "------------\n",
      "Loss 0.2891118824481964\n",
      "Epoch  101\n",
      "------------\n",
      "Loss 0.568931519985199\n",
      "Epoch  102\n",
      "------------\n",
      "Loss 0.2976139783859253\n",
      "Epoch  103\n",
      "------------\n",
      "Loss 0.8275103569030762\n",
      "Epoch  104\n",
      "------------\n",
      "Loss 1.8540157079696655\n",
      "Epoch  105\n",
      "------------\n",
      "Loss 0.437269389629364\n",
      "Epoch  106\n",
      "------------\n",
      "Loss 0.45126694440841675\n",
      "Epoch  107\n",
      "------------\n",
      "Loss 0.23087893426418304\n",
      "Epoch  108\n",
      "------------\n",
      "Loss 1.1552104949951172\n",
      "Epoch  109\n",
      "------------\n",
      "Loss 0.23357604444026947\n",
      "Epoch  110\n",
      "------------\n",
      "Loss 0.6226463317871094\n",
      "Epoch  111\n",
      "------------\n",
      "Loss 0.48632776737213135\n",
      "Epoch  112\n",
      "------------\n",
      "Loss 0.4666408598423004\n",
      "Epoch  113\n",
      "------------\n",
      "Loss 0.12880223989486694\n",
      "Epoch  114\n",
      "------------\n",
      "Loss 1.168735384941101\n",
      "Epoch  115\n",
      "------------\n",
      "Loss 0.5840811133384705\n",
      "Epoch  116\n",
      "------------\n",
      "Loss 0.17405632138252258\n",
      "Epoch  117\n",
      "------------\n",
      "Loss 0.32194381952285767\n",
      "Epoch  118\n",
      "------------\n",
      "Loss 0.7049580812454224\n",
      "Epoch  119\n",
      "------------\n",
      "Loss 0.37217122316360474\n",
      "Epoch  120\n",
      "------------\n",
      "Loss 1.0489461421966553\n",
      "Epoch  121\n",
      "------------\n",
      "Loss 0.19000881910324097\n",
      "Epoch  122\n",
      "------------\n",
      "Loss 0.23353783786296844\n",
      "Epoch  123\n",
      "------------\n",
      "Loss 0.22687400877475739\n",
      "Epoch  124\n",
      "------------\n",
      "Loss 0.1370871365070343\n",
      "Epoch  125\n",
      "------------\n",
      "Loss 0.29472115635871887\n",
      "Epoch  126\n",
      "------------\n",
      "Loss 0.23579558730125427\n",
      "Epoch  127\n",
      "------------\n",
      "Loss 0.24451184272766113\n",
      "Epoch  128\n",
      "------------\n",
      "Loss 0.15773916244506836\n",
      "Epoch  129\n",
      "------------\n",
      "Loss 1.4463047981262207\n",
      "Epoch  130\n",
      "------------\n",
      "Loss 0.23759004473686218\n",
      "Epoch  131\n",
      "------------\n",
      "Loss 0.19289687275886536\n",
      "Epoch  132\n",
      "------------\n",
      "Loss 1.323349118232727\n",
      "Epoch  133\n",
      "------------\n",
      "Loss 0.26751086115837097\n",
      "Epoch  134\n",
      "------------\n",
      "Loss 0.5159381628036499\n",
      "Epoch  135\n",
      "------------\n",
      "Loss 0.6607846021652222\n",
      "Epoch  136\n",
      "------------\n",
      "Loss 0.2870662808418274\n",
      "Epoch  137\n",
      "------------\n",
      "Loss 0.2653121054172516\n",
      "Epoch  138\n",
      "------------\n",
      "Loss 0.2833186984062195\n",
      "Epoch  139\n",
      "------------\n",
      "Loss 0.34494176506996155\n",
      "Epoch  140\n",
      "------------\n",
      "Loss 0.3104085922241211\n",
      "Epoch  141\n",
      "------------\n",
      "Loss 2.1373095512390137\n",
      "Epoch  142\n",
      "------------\n",
      "Loss 0.2697692811489105\n",
      "Epoch  143\n",
      "------------\n",
      "Loss 1.8892326354980469\n",
      "Epoch  144\n",
      "------------\n",
      "Loss 0.21353058516979218\n",
      "Epoch  145\n",
      "------------\n",
      "Loss 0.04778794199228287\n",
      "Epoch  146\n",
      "------------\n",
      "Loss 0.21271400153636932\n",
      "Epoch  147\n",
      "------------\n",
      "Loss 0.4256671071052551\n",
      "Epoch  148\n",
      "------------\n",
      "Loss 0.2331155389547348\n",
      "Epoch  149\n",
      "------------\n",
      "Loss 0.5064341425895691\n",
      "Epoch  150\n",
      "------------\n",
      "Loss 0.29353734850883484\n",
      "Epoch  151\n",
      "------------\n",
      "Loss 0.17428526282310486\n",
      "Epoch  152\n",
      "------------\n",
      "Loss 0.21405291557312012\n",
      "Epoch  153\n",
      "------------\n",
      "Loss 0.19728368520736694\n",
      "Epoch  154\n",
      "------------\n",
      "Loss 0.4002241790294647\n",
      "Epoch  155\n",
      "------------\n",
      "Loss 0.31271737813949585\n",
      "Epoch  156\n",
      "------------\n",
      "Loss 0.2730281352996826\n",
      "Epoch  157\n",
      "------------\n",
      "Loss 0.21505729854106903\n",
      "Epoch  158\n",
      "------------\n",
      "Loss 0.15598176419734955\n",
      "Epoch  159\n",
      "------------\n",
      "Loss 4.050135612487793\n",
      "Epoch  160\n",
      "------------\n",
      "Loss 1.0880705118179321\n",
      "Epoch  161\n",
      "------------\n",
      "Loss 0.24794740974903107\n",
      "Epoch  162\n",
      "------------\n",
      "Loss 0.4450395405292511\n",
      "Epoch  163\n",
      "------------\n",
      "Loss 0.3743945360183716\n",
      "Epoch  164\n",
      "------------\n",
      "Loss 0.36123085021972656\n",
      "Epoch  165\n",
      "------------\n",
      "Loss 0.2851797640323639\n",
      "Epoch  166\n",
      "------------\n",
      "Loss 1.485116720199585\n",
      "Epoch  167\n",
      "------------\n",
      "Loss 0.2461245059967041\n",
      "Epoch  168\n",
      "------------\n",
      "Loss 0.16400890052318573\n",
      "Epoch  169\n",
      "------------\n",
      "Loss 0.37433552742004395\n",
      "Epoch  170\n",
      "------------\n",
      "Loss 0.22247180342674255\n",
      "Epoch  171\n",
      "------------\n",
      "Loss 0.08166748285293579\n",
      "Epoch  172\n",
      "------------\n",
      "Loss 3.880655527114868\n",
      "Epoch  173\n",
      "------------\n",
      "Loss 0.6023067831993103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  174\n",
      "------------\n",
      "Loss 0.19863158464431763\n",
      "Epoch  175\n",
      "------------\n",
      "Loss 0.13305261731147766\n",
      "Epoch  176\n",
      "------------\n",
      "Loss 0.34714922308921814\n",
      "Epoch  177\n",
      "------------\n",
      "Loss 0.2647610306739807\n",
      "Epoch  178\n",
      "------------\n",
      "Loss 1.0812830924987793\n",
      "Epoch  179\n",
      "------------\n",
      "Loss 0.2795872390270233\n",
      "Epoch  180\n",
      "------------\n",
      "Loss 1.502698302268982\n",
      "Epoch  181\n",
      "------------\n",
      "Loss 0.26199790835380554\n",
      "Epoch  182\n",
      "------------\n",
      "Loss 1.1468106508255005\n",
      "Epoch  183\n",
      "------------\n",
      "Loss 0.320489764213562\n",
      "Epoch  184\n",
      "------------\n",
      "Loss 0.09949745237827301\n",
      "Epoch  185\n",
      "------------\n",
      "Loss 0.446553498506546\n",
      "Epoch  186\n",
      "------------\n",
      "Loss 0.5166959762573242\n",
      "Epoch  187\n",
      "------------\n",
      "Loss 0.4070974588394165\n",
      "Epoch  188\n",
      "------------\n",
      "Loss 0.11185409128665924\n",
      "Epoch  189\n",
      "------------\n",
      "Loss 0.29403993487358093\n",
      "Epoch  190\n",
      "------------\n",
      "Loss 0.4319054186344147\n",
      "Epoch  191\n",
      "------------\n",
      "Loss 0.39477303624153137\n",
      "Epoch  192\n",
      "------------\n",
      "Loss 0.7031095027923584\n",
      "Epoch  193\n",
      "------------\n",
      "Loss 0.26564157009124756\n",
      "Epoch  194\n",
      "------------\n",
      "Loss 0.26450082659721375\n",
      "Epoch  195\n",
      "------------\n",
      "Loss 0.2291502058506012\n",
      "Epoch  196\n",
      "------------\n",
      "Loss 0.4246814548969269\n",
      "Epoch  197\n",
      "------------\n",
      "Loss 0.18486908078193665\n",
      "Epoch  198\n",
      "------------\n",
      "Loss 0.4556184411048889\n",
      "Epoch  199\n",
      "------------\n",
      "Loss 0.646551251411438\n",
      "Epoch  200\n",
      "------------\n",
      "Loss 0.1838919222354889\n",
      "Epoch  201\n",
      "------------\n",
      "Loss 0.2154393494129181\n",
      "Epoch  202\n",
      "------------\n",
      "Loss 0.399345725774765\n",
      "Epoch  203\n",
      "------------\n",
      "Loss 0.2672120928764343\n",
      "Epoch  204\n",
      "------------\n",
      "Loss 0.10071519017219543\n",
      "Epoch  205\n",
      "------------\n",
      "Loss 0.2162153124809265\n",
      "Epoch  206\n",
      "------------\n",
      "Loss 0.19327375292778015\n",
      "Epoch  207\n",
      "------------\n",
      "Loss 0.21355947852134705\n",
      "Epoch  208\n",
      "------------\n",
      "Loss 0.3982415795326233\n",
      "Epoch  209\n",
      "------------\n",
      "Loss 0.2855689227581024\n",
      "Epoch  210\n",
      "------------\n",
      "Loss 0.13059258460998535\n",
      "Epoch  211\n",
      "------------\n",
      "Loss 0.1555795669555664\n",
      "Epoch  212\n",
      "------------\n",
      "Loss 0.28637659549713135\n",
      "Epoch  213\n",
      "------------\n",
      "Loss 0.36406558752059937\n",
      "Epoch  214\n",
      "------------\n",
      "Loss 0.09588590264320374\n",
      "Epoch  215\n",
      "------------\n",
      "Loss 0.2170003354549408\n",
      "Epoch  216\n",
      "------------\n",
      "Loss 0.15818217396736145\n",
      "Epoch  217\n",
      "------------\n",
      "Loss 0.17200207710266113\n",
      "Epoch  218\n",
      "------------\n",
      "Loss 0.11109073460102081\n",
      "Epoch  219\n",
      "------------\n",
      "Loss 0.29287469387054443\n",
      "Epoch  220\n",
      "------------\n",
      "Loss 0.42643100023269653\n",
      "Epoch  221\n",
      "------------\n",
      "Loss 0.25132811069488525\n",
      "Epoch  222\n",
      "------------\n",
      "Loss 0.27068039774894714\n",
      "Epoch  223\n",
      "------------\n",
      "Loss 0.07179960608482361\n",
      "Epoch  224\n",
      "------------\n",
      "Loss 1.4191925525665283\n",
      "Epoch  225\n",
      "------------\n",
      "Loss 0.23762395977973938\n",
      "Epoch  226\n",
      "------------\n",
      "Loss 0.08934816718101501\n",
      "Epoch  227\n",
      "------------\n",
      "Loss 0.9588376879692078\n",
      "Epoch  228\n",
      "------------\n",
      "Loss 0.28626206517219543\n",
      "Epoch  229\n",
      "------------\n",
      "Loss 0.9993444085121155\n",
      "Epoch  230\n",
      "------------\n",
      "Loss 0.08493085205554962\n",
      "Epoch  231\n",
      "------------\n",
      "Loss 0.17718720436096191\n",
      "Epoch  232\n",
      "------------\n",
      "Loss 0.19577498733997345\n",
      "Epoch  233\n",
      "------------\n",
      "Loss 0.09168072789907455\n",
      "Epoch  234\n",
      "------------\n",
      "Loss 0.1179385781288147\n",
      "Epoch  235\n",
      "------------\n",
      "Loss 0.28959932923316956\n",
      "Epoch  236\n",
      "------------\n",
      "Loss 0.17088831961154938\n",
      "Epoch  237\n",
      "------------\n",
      "Loss 0.21866723895072937\n",
      "Epoch  238\n",
      "------------\n",
      "Loss 2.009812355041504\n",
      "Epoch  239\n",
      "------------\n",
      "Loss 0.14136117696762085\n",
      "Epoch  240\n",
      "------------\n",
      "Loss 0.250055193901062\n",
      "Epoch  241\n",
      "------------\n",
      "Loss 0.46509140729904175\n",
      "Epoch  242\n",
      "------------\n",
      "Loss 0.46214112639427185\n",
      "Epoch  243\n",
      "------------\n",
      "Loss 0.10112621635198593\n",
      "Epoch  244\n",
      "------------\n",
      "Loss 0.1888296902179718\n",
      "Epoch  245\n",
      "------------\n",
      "Loss 0.1954655945301056\n",
      "Epoch  246\n",
      "------------\n",
      "Loss 0.21826599538326263\n",
      "Epoch  247\n",
      "------------\n",
      "Loss 0.1301773488521576\n",
      "Epoch  248\n",
      "------------\n",
      "Loss 0.22418682277202606\n",
      "Epoch  249\n",
      "------------\n",
      "Loss 0.8587750196456909\n",
      "Epoch  250\n",
      "------------\n",
      "Loss 0.13508930802345276\n",
      "Epoch  251\n",
      "------------\n",
      "Loss 0.2018483281135559\n",
      "Epoch  252\n",
      "------------\n",
      "Loss 0.22209808230400085\n",
      "Epoch  253\n",
      "------------\n",
      "Loss 0.1726262867450714\n",
      "Epoch  254\n",
      "------------\n",
      "Loss 0.12086480110883713\n",
      "Epoch  255\n",
      "------------\n",
      "Loss 0.17421993613243103\n",
      "Epoch  256\n",
      "------------\n",
      "Loss 0.48518267273902893\n",
      "Epoch  257\n",
      "------------\n",
      "Loss 0.19441735744476318\n",
      "Epoch  258\n",
      "------------\n",
      "Loss 0.10847564786672592\n",
      "Epoch  259\n",
      "------------\n",
      "Loss 0.02338266931474209\n",
      "Epoch  260\n",
      "------------\n",
      "Loss 0.1814582198858261\n",
      "Epoch  261\n",
      "------------\n",
      "Loss 0.3984111547470093\n",
      "Epoch  262\n",
      "------------\n",
      "Loss 0.09765159338712692\n",
      "Epoch  263\n",
      "------------\n",
      "Loss 0.12901216745376587\n",
      "Epoch  264\n",
      "------------\n",
      "Loss 0.059652455151081085\n",
      "Epoch  265\n",
      "------------\n",
      "Loss 0.4685894846916199\n",
      "Epoch  266\n",
      "------------\n",
      "Loss 0.20175836980342865\n",
      "Epoch  267\n",
      "------------\n",
      "Loss 0.4917990267276764\n",
      "Epoch  268\n",
      "------------\n",
      "Loss 0.8128054141998291\n",
      "Epoch  269\n",
      "------------\n",
      "Loss 0.4599868655204773\n",
      "Epoch  270\n",
      "------------\n",
      "Loss 0.12166240066289902\n",
      "Epoch  271\n",
      "------------\n",
      "Loss 0.1834763139486313\n",
      "Epoch  272\n",
      "------------\n",
      "Loss 1.2887933254241943\n",
      "Epoch  273\n",
      "------------\n",
      "Loss 0.7262470126152039\n",
      "Epoch  274\n",
      "------------\n",
      "Loss 0.9172890782356262\n",
      "Epoch  275\n",
      "------------\n",
      "Loss 0.1095125749707222\n",
      "Epoch  276\n",
      "------------\n",
      "Loss 0.41942015290260315\n",
      "Epoch  277\n",
      "------------\n",
      "Loss 0.25280943512916565\n",
      "Epoch  278\n",
      "------------\n",
      "Loss 1.5269813537597656\n",
      "Epoch  279\n",
      "------------\n",
      "Loss 0.22676986455917358\n",
      "Epoch  280\n",
      "------------\n",
      "Loss 0.1914391815662384\n",
      "Epoch  281\n",
      "------------\n",
      "Loss 0.08473342657089233\n",
      "Epoch  282\n",
      "------------\n",
      "Loss 0.20830273628234863\n",
      "Epoch  283\n",
      "------------\n",
      "Loss 0.19623523950576782\n",
      "Epoch  284\n",
      "------------\n",
      "Loss 0.0976799875497818\n",
      "Epoch  285\n",
      "------------\n",
      "Loss 0.4984778165817261\n",
      "Epoch  286\n",
      "------------\n",
      "Loss 1.545732855796814\n",
      "Epoch  287\n",
      "------------\n",
      "Loss 0.23035241663455963\n",
      "Epoch  288\n",
      "------------\n",
      "Loss 0.20192843675613403\n",
      "Epoch  289\n",
      "------------\n",
      "Loss 0.5769491195678711\n",
      "Epoch  290\n",
      "------------\n",
      "Loss 0.9623992443084717\n",
      "Epoch  291\n",
      "------------\n",
      "Loss 2.047969102859497\n",
      "Epoch  292\n",
      "------------\n",
      "Loss 0.5342583060264587\n",
      "Epoch  293\n",
      "------------\n",
      "Loss 0.4052189290523529\n",
      "Epoch  294\n",
      "------------\n",
      "Loss 0.4612274765968323\n",
      "Epoch  295\n",
      "------------\n",
      "Loss 1.0297458171844482\n",
      "Epoch  296\n",
      "------------\n",
      "Loss 0.5389388203620911\n",
      "Epoch  297\n",
      "------------\n",
      "Loss 0.6235746145248413\n",
      "Epoch  298\n",
      "------------\n",
      "Loss 0.2858908772468567\n",
      "Epoch  299\n",
      "------------\n",
      "Loss 0.4553057849407196\n",
      "Epoch  300\n",
      "------------\n",
      "Loss 0.2945880889892578\n",
      "Epoch  301\n",
      "------------\n",
      "Loss 0.15341782569885254\n",
      "Epoch  302\n",
      "------------\n",
      "Loss 0.35821330547332764\n",
      "Epoch  303\n",
      "------------\n",
      "Loss 0.07648159563541412\n",
      "Epoch  304\n",
      "------------\n",
      "Loss 0.16969594359397888\n",
      "Epoch  305\n",
      "------------\n",
      "Loss 0.12693054974079132\n",
      "Epoch  306\n",
      "------------\n",
      "Loss 0.11508524417877197\n",
      "Epoch  307\n",
      "------------\n",
      "Loss 0.4684070646762848\n",
      "Epoch  308\n",
      "------------\n",
      "Loss 0.051268070936203\n",
      "Epoch  309\n",
      "------------\n",
      "Loss 0.2684708535671234\n",
      "Epoch  310\n",
      "------------\n",
      "Loss 0.1870080828666687\n",
      "Epoch  311\n",
      "------------\n",
      "Loss 0.16757485270500183\n",
      "Epoch  312\n",
      "------------\n",
      "Loss 0.3584759533405304\n",
      "Epoch  313\n",
      "------------\n",
      "Loss 0.19945882260799408\n",
      "Epoch  314\n",
      "------------\n",
      "Loss 0.36825254559516907\n",
      "Epoch  315\n",
      "------------\n",
      "Loss 0.13959437608718872\n",
      "Epoch  316\n",
      "------------\n",
      "Loss 0.19540081918239594\n",
      "Epoch  317\n",
      "------------\n",
      "Loss 0.06197655200958252\n",
      "Epoch  318\n",
      "------------\n",
      "Loss 0.6332495808601379\n",
      "Epoch  319\n",
      "------------\n",
      "Loss 0.10007888823747635\n",
      "Epoch  320\n",
      "------------\n",
      "Loss 0.10045882314443588\n",
      "Epoch  321\n",
      "------------\n",
      "Loss 0.25330162048339844\n",
      "Epoch  322\n",
      "------------\n",
      "Loss 0.45967811346054077\n",
      "Epoch  323\n",
      "------------\n",
      "Loss 1.820221185684204\n",
      "Epoch  324\n",
      "------------\n",
      "Loss 0.2429630607366562\n",
      "Epoch  325\n",
      "------------\n",
      "Loss 0.24542395770549774\n",
      "Epoch  326\n",
      "------------\n",
      "Loss 0.16051159799098969\n",
      "Epoch  327\n",
      "------------\n",
      "Loss 0.19747917354106903\n",
      "Epoch  328\n",
      "------------\n",
      "Loss 0.15983068943023682\n",
      "Epoch  329\n",
      "------------\n",
      "Loss 0.20572543144226074\n",
      "Epoch  330\n",
      "------------\n",
      "Loss 0.15128527581691742\n",
      "Epoch  331\n",
      "------------\n",
      "Loss 0.0899047926068306\n",
      "Epoch  332\n",
      "------------\n",
      "Loss 1.5925536155700684\n",
      "Epoch  333\n",
      "------------\n",
      "Loss 0.06512267142534256\n",
      "Epoch  334\n",
      "------------\n",
      "Loss 0.15028148889541626\n",
      "Epoch  335\n",
      "------------\n",
      "Loss 0.04028834402561188\n",
      "Epoch  336\n",
      "------------\n",
      "Loss 0.44747674465179443\n",
      "Epoch  337\n",
      "------------\n",
      "Loss 0.2779240310192108\n",
      "Epoch  338\n",
      "------------\n",
      "Loss 3.0611467361450195\n",
      "Epoch  339\n",
      "------------\n",
      "Loss 0.13902729749679565\n",
      "Epoch  340\n",
      "------------\n",
      "Loss 0.2520386278629303\n",
      "Epoch  341\n",
      "------------\n",
      "Loss 0.2367316335439682\n",
      "Epoch  342\n",
      "------------\n",
      "Loss 0.5193021893501282\n",
      "Epoch  343\n",
      "------------\n",
      "Loss 0.322685569524765\n",
      "Epoch  344\n",
      "------------\n",
      "Loss 0.19841314852237701\n",
      "Epoch  345\n",
      "------------\n",
      "Loss 0.1396772563457489\n",
      "Epoch  346\n",
      "------------\n",
      "Loss 0.3196696639060974\n",
      "Epoch  347\n",
      "------------\n",
      "Loss 0.54705810546875\n",
      "Epoch  348\n",
      "------------\n",
      "Loss 0.3302273154258728\n",
      "Epoch  349\n",
      "------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.21461370587348938\n",
      "Epoch  350\n",
      "------------\n",
      "Loss 0.08079053461551666\n",
      "Epoch  351\n",
      "------------\n",
      "Loss 0.19984889030456543\n",
      "Epoch  352\n",
      "------------\n",
      "Loss 0.18941441178321838\n",
      "Epoch  353\n",
      "------------\n",
      "Loss 0.1125742644071579\n",
      "Epoch  354\n",
      "------------\n",
      "Loss 5.8687849044799805\n",
      "Epoch  355\n",
      "------------\n",
      "Loss 0.3541736602783203\n",
      "Epoch  356\n",
      "------------\n",
      "Loss 2.8715052604675293\n",
      "Epoch  357\n",
      "------------\n",
      "Loss 0.14649704098701477\n",
      "Epoch  358\n",
      "------------\n",
      "Loss 0.31270647048950195\n",
      "Epoch  359\n",
      "------------\n",
      "Loss 0.8310509324073792\n",
      "Epoch  360\n",
      "------------\n",
      "Loss 0.36560487747192383\n",
      "Epoch  361\n",
      "------------\n",
      "Loss 0.4988681674003601\n",
      "Epoch  362\n",
      "------------\n",
      "Loss 0.29078176617622375\n",
      "Epoch  363\n",
      "------------\n",
      "Loss 0.12670180201530457\n",
      "Epoch  364\n",
      "------------\n",
      "Loss 0.2657143175601959\n",
      "Epoch  365\n",
      "------------\n",
      "Loss 0.6066574454307556\n",
      "Epoch  366\n",
      "------------\n",
      "Loss 2.1050634384155273\n",
      "Epoch  367\n",
      "------------\n",
      "Loss 0.05124688148498535\n",
      "Epoch  368\n",
      "------------\n",
      "Loss 0.18209098279476166\n",
      "Epoch  369\n",
      "------------\n",
      "Loss 0.4440533518791199\n",
      "Epoch  370\n",
      "------------\n",
      "Loss 0.31164753437042236\n",
      "Epoch  371\n",
      "------------\n",
      "Loss 0.16036884486675262\n",
      "Epoch  372\n",
      "------------\n",
      "Loss 0.3668630123138428\n",
      "Epoch  373\n",
      "------------\n",
      "Loss 0.07475525885820389\n",
      "Epoch  374\n",
      "------------\n",
      "Loss 0.1485954076051712\n",
      "Epoch  375\n",
      "------------\n",
      "Loss 0.16982868313789368\n",
      "Epoch  376\n",
      "------------\n",
      "Loss 0.22162848711013794\n",
      "Epoch  377\n",
      "------------\n",
      "Loss 0.4482012987136841\n",
      "Epoch  378\n",
      "------------\n",
      "Loss 1.1130595207214355\n",
      "Epoch  379\n",
      "------------\n",
      "Loss 0.12380947172641754\n",
      "Epoch  380\n",
      "------------\n",
      "Loss 1.9574000835418701\n",
      "Epoch  381\n",
      "------------\n",
      "Loss 0.16006594896316528\n",
      "Epoch  382\n",
      "------------\n",
      "Loss 0.24815885722637177\n",
      "Epoch  383\n",
      "------------\n",
      "Loss 0.0761214941740036\n",
      "Epoch  384\n",
      "------------\n",
      "Loss 1.5391302108764648\n",
      "Epoch  385\n",
      "------------\n",
      "Loss 0.10718956589698792\n",
      "Epoch  386\n",
      "------------\n",
      "Loss 0.12525136768817902\n",
      "Epoch  387\n",
      "------------\n",
      "Loss 0.1318061202764511\n",
      "Epoch  388\n",
      "------------\n",
      "Loss 0.21579357981681824\n",
      "Epoch  389\n",
      "------------\n",
      "Loss 0.07466097176074982\n",
      "Epoch  390\n",
      "------------\n",
      "Loss 0.10293489694595337\n",
      "Epoch  391\n",
      "------------\n",
      "Loss 0.08979607373476028\n",
      "Epoch  392\n",
      "------------\n",
      "Loss 0.3602437376976013\n",
      "Epoch  393\n",
      "------------\n",
      "Loss 0.18473711609840393\n",
      "Epoch  394\n",
      "------------\n",
      "Loss 0.12612171471118927\n",
      "Epoch  395\n",
      "------------\n",
      "Loss 0.17790141701698303\n",
      "Epoch  396\n",
      "------------\n",
      "Loss 0.1974528580904007\n",
      "Epoch  397\n",
      "------------\n",
      "Loss 0.3453391194343567\n",
      "Epoch  398\n",
      "------------\n",
      "Loss 0.019873032346367836\n",
      "Epoch  399\n",
      "------------\n",
      "Loss 1.8288805484771729\n",
      "Epoch  400\n",
      "------------\n",
      "Loss 0.44865915179252625\n",
      "Epoch  401\n",
      "------------\n",
      "Loss 0.4808243215084076\n",
      "Epoch  402\n",
      "------------\n",
      "Loss 0.10213134437799454\n",
      "Epoch  403\n",
      "------------\n",
      "Loss 1.638567328453064\n",
      "Epoch  404\n",
      "------------\n",
      "Loss 2.752145290374756\n",
      "Epoch  405\n",
      "------------\n",
      "Loss 0.24037225544452667\n",
      "Epoch  406\n",
      "------------\n",
      "Loss 0.32167497277259827\n",
      "Epoch  407\n",
      "------------\n",
      "Loss 0.1878480762243271\n",
      "Epoch  408\n",
      "------------\n",
      "Loss 0.15719366073608398\n",
      "Epoch  409\n",
      "------------\n",
      "Loss 0.8086201548576355\n",
      "Epoch  410\n",
      "------------\n",
      "Loss 0.11964447796344757\n",
      "Epoch  411\n",
      "------------\n",
      "Loss 0.21576158702373505\n",
      "Epoch  412\n",
      "------------\n",
      "Loss 0.2975780665874481\n",
      "Epoch  413\n",
      "------------\n",
      "Loss 0.6630270481109619\n",
      "Epoch  414\n",
      "------------\n",
      "Loss 0.3529636263847351\n",
      "Epoch  415\n",
      "------------\n",
      "Loss 0.34484297037124634\n",
      "Epoch  416\n",
      "------------\n",
      "Loss 0.33194172382354736\n",
      "Epoch  417\n",
      "------------\n",
      "Loss 0.08577417582273483\n",
      "Epoch  418\n",
      "------------\n",
      "Loss 0.2018907368183136\n",
      "Epoch  419\n",
      "------------\n",
      "Loss 0.16278667747974396\n",
      "Epoch  420\n",
      "------------\n",
      "Loss 0.6462252140045166\n",
      "Epoch  421\n",
      "------------\n",
      "Loss 0.34658515453338623\n",
      "Epoch  422\n",
      "------------\n",
      "Loss 0.26132649183273315\n",
      "Epoch  423\n",
      "------------\n",
      "Loss 0.12103532999753952\n",
      "Epoch  424\n",
      "------------\n",
      "Loss 0.18970489501953125\n",
      "Epoch  425\n",
      "------------\n",
      "Loss 0.07950226217508316\n",
      "Epoch  426\n",
      "------------\n",
      "Loss 0.15115736424922943\n",
      "Epoch  427\n",
      "------------\n",
      "Loss 0.1498568058013916\n",
      "Epoch  428\n",
      "------------\n",
      "Loss 1.2833434343338013\n",
      "Epoch  429\n",
      "------------\n",
      "Loss 0.2727559208869934\n",
      "Epoch  430\n",
      "------------\n",
      "Loss 0.07949124276638031\n",
      "Epoch  431\n",
      "------------\n",
      "Loss 1.052368402481079\n",
      "Epoch  432\n",
      "------------\n",
      "Loss 0.2188754826784134\n",
      "Epoch  433\n",
      "------------\n",
      "Loss 2.414553642272949\n",
      "Epoch  434\n",
      "------------\n",
      "Loss 0.051176298409700394\n",
      "Epoch  435\n",
      "------------\n",
      "Loss 0.12451508641242981\n",
      "Epoch  436\n",
      "------------\n",
      "Loss 0.09454283118247986\n",
      "Epoch  437\n",
      "------------\n",
      "Loss 0.18919044733047485\n",
      "Epoch  438\n",
      "------------\n",
      "Loss 0.6091333031654358\n",
      "Epoch  439\n",
      "------------\n",
      "Loss 0.2077237069606781\n",
      "Epoch  440\n",
      "------------\n",
      "Loss 0.11652261018753052\n",
      "Epoch  441\n",
      "------------\n",
      "Loss 1.1953145265579224\n",
      "Epoch  442\n",
      "------------\n",
      "Loss 0.05419861525297165\n",
      "Epoch  443\n",
      "------------\n",
      "Loss 0.22267073392868042\n",
      "Epoch  444\n",
      "------------\n",
      "Loss 0.39655545353889465\n",
      "Epoch  445\n",
      "------------\n",
      "Loss 0.17331212759017944\n",
      "Epoch  446\n",
      "------------\n",
      "Loss 0.2992982864379883\n",
      "Epoch  447\n",
      "------------\n",
      "Loss 0.09186865389347076\n",
      "Epoch  448\n",
      "------------\n",
      "Loss 0.11885489523410797\n",
      "Epoch  449\n",
      "------------\n",
      "Loss 0.14212293922901154\n",
      "Epoch  450\n",
      "------------\n",
      "Loss 0.28157538175582886\n",
      "Epoch  451\n",
      "------------\n",
      "Loss 0.09621523320674896\n",
      "Epoch  452\n",
      "------------\n",
      "Loss 3.770869731903076\n",
      "Epoch  453\n",
      "------------\n",
      "Loss 0.15768446028232574\n",
      "Epoch  454\n",
      "------------\n",
      "Loss 0.6126929521560669\n",
      "Epoch  455\n",
      "------------\n",
      "Loss 0.2531455457210541\n",
      "Epoch  456\n",
      "------------\n",
      "Loss 0.3833637833595276\n",
      "Epoch  457\n",
      "------------\n",
      "Loss 0.41162747144699097\n",
      "Epoch  458\n",
      "------------\n",
      "Loss 0.6498054265975952\n",
      "Epoch  459\n",
      "------------\n",
      "Loss 0.8368369936943054\n",
      "Epoch  460\n",
      "------------\n",
      "Loss 0.250069797039032\n",
      "Epoch  461\n",
      "------------\n",
      "Loss 2.1034398078918457\n",
      "Epoch  462\n",
      "------------\n",
      "Loss 0.07795335352420807\n",
      "Epoch  463\n",
      "------------\n",
      "Loss 1.2020219564437866\n",
      "Epoch  464\n",
      "------------\n",
      "Loss 0.21532683074474335\n",
      "Epoch  465\n",
      "------------\n",
      "Loss 1.5974971055984497\n",
      "Epoch  466\n",
      "------------\n",
      "Loss 0.5570678114891052\n",
      "Epoch  467\n",
      "------------\n",
      "Loss 1.725419521331787\n",
      "Epoch  468\n",
      "------------\n",
      "Loss 0.2203148901462555\n",
      "Epoch  469\n",
      "------------\n",
      "Loss 0.8143848776817322\n",
      "Epoch  470\n",
      "------------\n",
      "Loss 0.2721637487411499\n",
      "Epoch  471\n",
      "------------\n",
      "Loss 0.09318371117115021\n",
      "Epoch  472\n",
      "------------\n",
      "Loss 0.10231831669807434\n",
      "Epoch  473\n",
      "------------\n",
      "Loss 0.6776348352432251\n",
      "Epoch  474\n",
      "------------\n",
      "Loss 0.4123445153236389\n",
      "Epoch  475\n",
      "------------\n",
      "Loss 0.3294937014579773\n",
      "Epoch  476\n",
      "------------\n",
      "Loss 0.16725203394889832\n",
      "Epoch  477\n",
      "------------\n",
      "Loss 0.24666547775268555\n",
      "Epoch  478\n",
      "------------\n",
      "Loss 0.19472536444664001\n",
      "Epoch  479\n",
      "------------\n",
      "Loss 0.11667229235172272\n",
      "Epoch  480\n",
      "------------\n",
      "Loss 0.5306155681610107\n",
      "Epoch  481\n",
      "------------\n",
      "Loss 0.5736733078956604\n",
      "Epoch  482\n",
      "------------\n",
      "Loss 0.40478062629699707\n",
      "Epoch  483\n",
      "------------\n",
      "Loss 0.4124661386013031\n",
      "Epoch  484\n",
      "------------\n",
      "Loss 0.3082842528820038\n",
      "Epoch  485\n",
      "------------\n",
      "Loss 0.1384025365114212\n",
      "Epoch  486\n",
      "------------\n",
      "Loss 0.2991730570793152\n",
      "Epoch  487\n",
      "------------\n",
      "Loss 0.11314161121845245\n",
      "Epoch  488\n",
      "------------\n",
      "Loss 0.3796931207180023\n",
      "Epoch  489\n",
      "------------\n",
      "Loss 0.30164411664009094\n",
      "Epoch  490\n",
      "------------\n",
      "Loss 0.06648685038089752\n",
      "Epoch  491\n",
      "------------\n",
      "Loss 0.35777145624160767\n",
      "Epoch  492\n",
      "------------\n",
      "Loss 0.16839715838432312\n",
      "Epoch  493\n",
      "------------\n",
      "Loss 0.14795413613319397\n",
      "Epoch  494\n",
      "------------\n",
      "Loss 0.8399847745895386\n",
      "Epoch  495\n",
      "------------\n",
      "Loss 0.2516268491744995\n",
      "Epoch  496\n",
      "------------\n",
      "Loss 0.40157952904701233\n",
      "Epoch  497\n",
      "------------\n",
      "Loss 0.14630834758281708\n",
      "Epoch  498\n",
      "------------\n",
      "Loss 1.5494464635849\n",
      "Epoch  499\n",
      "------------\n",
      "Loss 0.11926424503326416\n",
      "Epoch  500\n",
      "------------\n",
      "Loss 0.14524370431900024\n",
      "Epoch  501\n",
      "------------\n",
      "Loss 0.10817305743694305\n",
      "Epoch  502\n",
      "------------\n",
      "Loss 0.2383243292570114\n",
      "Epoch  503\n",
      "------------\n",
      "Loss 0.4088677763938904\n",
      "Epoch  504\n",
      "------------\n",
      "Loss 0.21326062083244324\n",
      "Epoch  505\n",
      "------------\n",
      "Loss 0.8107848763465881\n",
      "Epoch  506\n",
      "------------\n",
      "Loss 0.13295480608940125\n",
      "Epoch  507\n",
      "------------\n",
      "Loss 0.19201549887657166\n",
      "Epoch  508\n",
      "------------\n",
      "Loss 0.14660891890525818\n",
      "Epoch  509\n",
      "------------\n",
      "Loss 0.13493406772613525\n",
      "Epoch  510\n",
      "------------\n",
      "Loss 0.15545694530010223\n",
      "Epoch  511\n",
      "------------\n",
      "Loss 1.4593552350997925\n",
      "Epoch  512\n",
      "------------\n",
      "Loss 0.14955031871795654\n",
      "Epoch  513\n",
      "------------\n",
      "Loss 0.21654129028320312\n",
      "Epoch  514\n",
      "------------\n",
      "Loss 0.12814010679721832\n",
      "Epoch  515\n",
      "------------\n",
      "Loss 0.18787062168121338\n",
      "Epoch  516\n",
      "------------\n",
      "Loss 1.1991798877716064\n",
      "Epoch  517\n",
      "------------\n",
      "Loss 0.48464375734329224\n",
      "Epoch  518\n",
      "------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1.3447611331939697\n",
      "Epoch  519\n",
      "------------\n",
      "Loss 0.12362032383680344\n",
      "Epoch  520\n",
      "------------\n",
      "Loss 0.1713598519563675\n",
      "Epoch  521\n",
      "------------\n",
      "Loss 0.1313333362340927\n",
      "Epoch  522\n",
      "------------\n",
      "Loss 0.19222547113895416\n",
      "Epoch  523\n",
      "------------\n",
      "Loss 0.4047573208808899\n",
      "Epoch  524\n",
      "------------\n",
      "Loss 0.49853515625\n",
      "Epoch  525\n",
      "------------\n",
      "Loss 0.15362900495529175\n",
      "Epoch  526\n",
      "------------\n",
      "Loss 0.13417068123817444\n",
      "Epoch  527\n",
      "------------\n",
      "Loss 0.17510591447353363\n",
      "Epoch  528\n",
      "------------\n",
      "Loss 0.1651243269443512\n",
      "Epoch  529\n",
      "------------\n",
      "Loss 0.34908851981163025\n",
      "Epoch  530\n",
      "------------\n",
      "Loss 2.812795400619507\n",
      "Epoch  531\n",
      "------------\n",
      "Loss 0.1567145735025406\n",
      "Epoch  532\n",
      "------------\n",
      "Loss 0.12899407744407654\n",
      "Epoch  533\n",
      "------------\n",
      "Loss 0.09656067192554474\n",
      "Epoch  534\n",
      "------------\n",
      "Loss 1.430200219154358\n",
      "Epoch  535\n",
      "------------\n",
      "Loss 0.21564261615276337\n",
      "Epoch  536\n",
      "------------\n",
      "Loss 0.08160051703453064\n",
      "Epoch  537\n",
      "------------\n",
      "Loss 6.5515336990356445\n",
      "Epoch  538\n",
      "------------\n",
      "Loss 0.32313936948776245\n",
      "Epoch  539\n",
      "------------\n",
      "Loss 0.4544088840484619\n",
      "Epoch  540\n",
      "------------\n",
      "Loss 0.40645769238471985\n",
      "Epoch  541\n",
      "------------\n",
      "Loss 0.15356256067752838\n",
      "Epoch  542\n",
      "------------\n",
      "Loss 0.5330972671508789\n",
      "Epoch  543\n",
      "------------\n",
      "Loss 0.12083268165588379\n",
      "Epoch  544\n",
      "------------\n",
      "Loss 0.18983712792396545\n",
      "Epoch  545\n",
      "------------\n",
      "Loss 0.1159086674451828\n",
      "Epoch  546\n",
      "------------\n",
      "Loss 0.2919013500213623\n",
      "Epoch  547\n",
      "------------\n",
      "Loss 1.8670880794525146\n",
      "Epoch  548\n",
      "------------\n",
      "Loss 0.18532979488372803\n",
      "Epoch  549\n",
      "------------\n",
      "Loss 0.35722973942756653\n",
      "Epoch  550\n",
      "------------\n",
      "Loss 0.207498699426651\n",
      "Epoch  551\n",
      "------------\n",
      "Loss 0.43443819880485535\n",
      "Epoch  552\n",
      "------------\n",
      "Loss 0.12394542992115021\n",
      "Epoch  553\n",
      "------------\n",
      "Loss 0.07460781186819077\n",
      "Epoch  554\n",
      "------------\n",
      "Loss 0.15338364243507385\n",
      "Epoch  555\n",
      "------------\n",
      "Loss 0.1886894553899765\n",
      "Epoch  556\n",
      "------------\n",
      "Loss 0.2282167673110962\n",
      "Epoch  557\n",
      "------------\n",
      "Loss 0.5198356509208679\n",
      "Epoch  558\n",
      "------------\n",
      "Loss 0.12831538915634155\n",
      "Epoch  559\n",
      "------------\n",
      "Loss 0.09530848264694214\n",
      "Epoch  560\n",
      "------------\n",
      "Loss 0.49609866738319397\n",
      "Epoch  561\n",
      "------------\n",
      "Loss 0.28319981694221497\n",
      "Epoch  562\n",
      "------------\n",
      "Loss 0.17021147906780243\n",
      "Epoch  563\n",
      "------------\n",
      "Loss 0.14551077783107758\n",
      "Epoch  564\n",
      "------------\n",
      "Loss 0.199082612991333\n",
      "Epoch  565\n",
      "------------\n",
      "Loss 0.9412641525268555\n",
      "Epoch  566\n",
      "------------\n",
      "Loss 0.24348938465118408\n",
      "Epoch  567\n",
      "------------\n",
      "Loss 0.392865389585495\n",
      "Epoch  568\n",
      "------------\n",
      "Loss 0.32387101650238037\n",
      "Epoch  569\n",
      "------------\n",
      "Loss 0.3756978511810303\n",
      "Epoch  570\n",
      "------------\n",
      "Loss 0.30691248178482056\n",
      "Epoch  571\n",
      "------------\n",
      "Loss 0.5145809650421143\n",
      "Epoch  572\n",
      "------------\n",
      "Loss 0.07086838036775589\n",
      "Epoch  573\n",
      "------------\n",
      "Loss 0.2264854609966278\n",
      "Epoch  574\n",
      "------------\n",
      "Loss 0.2189045250415802\n",
      "Epoch  575\n",
      "------------\n",
      "Loss 0.19554345309734344\n",
      "Epoch  576\n",
      "------------\n",
      "Loss 0.6777989268302917\n",
      "Epoch  577\n",
      "------------\n",
      "Loss 0.5467031598091125\n",
      "Epoch  578\n",
      "------------\n",
      "Loss 0.15917709469795227\n",
      "Epoch  579\n",
      "------------\n",
      "Loss 0.13045339286327362\n",
      "Epoch  580\n",
      "------------\n",
      "Loss 0.18086957931518555\n",
      "Epoch  581\n",
      "------------\n",
      "Loss 0.2535490393638611\n",
      "Epoch  582\n",
      "------------\n",
      "Loss 0.11779666692018509\n",
      "Epoch  583\n",
      "------------\n",
      "Loss 0.2743867039680481\n",
      "Epoch  584\n",
      "------------\n",
      "Loss 0.8696363568305969\n",
      "Epoch  585\n",
      "------------\n",
      "Loss 0.18031686544418335\n",
      "Epoch  586\n",
      "------------\n",
      "Loss 0.13092230260372162\n",
      "Epoch  587\n",
      "------------\n",
      "Loss 0.30536949634552\n",
      "Epoch  588\n",
      "------------\n",
      "Loss 0.1953456699848175\n",
      "Epoch  589\n",
      "------------\n",
      "Loss 0.3574248254299164\n",
      "Epoch  590\n",
      "------------\n",
      "Loss 0.16231262683868408\n",
      "Epoch  591\n",
      "------------\n",
      "Loss 0.23117294907569885\n",
      "Epoch  592\n",
      "------------\n",
      "Loss 0.23038725554943085\n",
      "Epoch  593\n",
      "------------\n",
      "Loss 0.0986621305346489\n",
      "Epoch  594\n",
      "------------\n",
      "Loss 0.3548862338066101\n",
      "Epoch  595\n",
      "------------\n",
      "Loss 0.2233271598815918\n",
      "Epoch  596\n",
      "------------\n",
      "Loss 0.2882547974586487\n",
      "Epoch  597\n",
      "------------\n",
      "Loss 0.08231844753026962\n",
      "Epoch  598\n",
      "------------\n",
      "Loss 0.35800182819366455\n",
      "Epoch  599\n",
      "------------\n",
      "Loss 0.25618958473205566\n",
      "Epoch  600\n",
      "------------\n",
      "Loss 0.09585224092006683\n",
      "Epoch  601\n",
      "------------\n",
      "Loss 0.2188173234462738\n",
      "Epoch  602\n",
      "------------\n",
      "Loss 0.370119571685791\n",
      "Epoch  603\n",
      "------------\n",
      "Loss 0.15902285277843475\n",
      "Epoch  604\n",
      "------------\n",
      "Loss 0.11009436845779419\n",
      "Epoch  605\n",
      "------------\n",
      "Loss 1.8638882637023926\n",
      "Epoch  606\n",
      "------------\n",
      "Loss 0.1705022156238556\n",
      "Epoch  607\n",
      "------------\n",
      "Loss 3.2539963722229004\n",
      "Epoch  608\n",
      "------------\n",
      "Loss 0.2688673734664917\n",
      "Epoch  609\n",
      "------------\n",
      "Loss 0.15344272553920746\n",
      "Epoch  610\n",
      "------------\n",
      "Loss 0.3725890517234802\n",
      "Epoch  611\n",
      "------------\n",
      "Loss 0.0735669732093811\n",
      "Epoch  612\n",
      "------------\n",
      "Loss 0.2663251459598541\n",
      "Epoch  613\n",
      "------------\n",
      "Loss 0.10695917904376984\n",
      "Epoch  614\n",
      "------------\n",
      "Loss 0.27611005306243896\n",
      "Epoch  615\n",
      "------------\n",
      "Loss 0.5766773819923401\n",
      "Epoch  616\n",
      "------------\n",
      "Loss 0.4186948239803314\n",
      "Epoch  617\n",
      "------------\n",
      "Loss 2.2597012519836426\n",
      "Epoch  618\n",
      "------------\n",
      "Loss 0.1952386200428009\n",
      "Epoch  619\n",
      "------------\n",
      "Loss 0.13089695572853088\n",
      "Epoch  620\n",
      "------------\n",
      "Loss 0.30869659781455994\n",
      "Epoch  621\n",
      "------------\n",
      "Loss 1.0331180095672607\n",
      "Epoch  622\n",
      "------------\n",
      "Loss 0.18393151462078094\n",
      "Epoch  623\n",
      "------------\n",
      "Loss 0.23935189843177795\n",
      "Epoch  624\n",
      "------------\n",
      "Loss 3.646714210510254\n",
      "Epoch  625\n",
      "------------\n",
      "Loss 0.19604556262493134\n",
      "Epoch  626\n",
      "------------\n",
      "Loss 0.2711222767829895\n",
      "Epoch  627\n",
      "------------\n",
      "Loss 0.526260495185852\n",
      "Epoch  628\n",
      "------------\n",
      "Loss 0.2734983265399933\n",
      "Epoch  629\n",
      "------------\n",
      "Loss 0.20620685815811157\n",
      "Epoch  630\n",
      "------------\n",
      "Loss 0.14062848687171936\n",
      "Epoch  631\n",
      "------------\n",
      "Loss 0.2871941030025482\n",
      "Epoch  632\n",
      "------------\n",
      "Loss 0.1361103057861328\n",
      "Epoch  633\n",
      "------------\n",
      "Loss 0.1759496033191681\n",
      "Epoch  634\n",
      "------------\n",
      "Loss 3.421677589416504\n",
      "Epoch  635\n",
      "------------\n",
      "Loss 0.24065494537353516\n",
      "Epoch  636\n",
      "------------\n",
      "Loss 0.24216599762439728\n",
      "Epoch  637\n",
      "------------\n",
      "Loss 0.13033823668956757\n",
      "Epoch  638\n",
      "------------\n",
      "Loss 0.16315387189388275\n",
      "Epoch  639\n",
      "------------\n",
      "Loss 0.15704670548439026\n",
      "Epoch  640\n",
      "------------\n",
      "Loss 0.23415657877922058\n",
      "Epoch  641\n",
      "------------\n",
      "Loss 0.18268924951553345\n",
      "Epoch  642\n",
      "------------\n",
      "Loss 0.14629940688610077\n",
      "Epoch  643\n",
      "------------\n",
      "Loss 0.5976873636245728\n",
      "Epoch  644\n",
      "------------\n",
      "Loss 1.5159868001937866\n",
      "Epoch  645\n",
      "------------\n",
      "Loss 0.2075675129890442\n",
      "Epoch  646\n",
      "------------\n",
      "Loss 0.16046559810638428\n",
      "Epoch  647\n",
      "------------\n",
      "Loss 0.19947656989097595\n",
      "Epoch  648\n",
      "------------\n",
      "Loss 0.08562910556793213\n",
      "Epoch  649\n",
      "------------\n",
      "Loss 0.552878201007843\n",
      "Epoch  650\n",
      "------------\n",
      "Loss 0.6431550979614258\n",
      "Epoch  651\n",
      "------------\n",
      "Loss 1.517026662826538\n",
      "Epoch  652\n",
      "------------\n",
      "Loss 0.37010306119918823\n",
      "Epoch  653\n",
      "------------\n",
      "Loss 0.15441542863845825\n",
      "Epoch  654\n",
      "------------\n",
      "Loss 0.18113505840301514\n",
      "Epoch  655\n",
      "------------\n",
      "Loss 0.48263904452323914\n",
      "Epoch  656\n",
      "------------\n",
      "Loss 0.1954970359802246\n",
      "Epoch  657\n",
      "------------\n",
      "Loss 0.08330169320106506\n",
      "Epoch  658\n",
      "------------\n",
      "Loss 0.12304205447435379\n",
      "Epoch  659\n",
      "------------\n",
      "Loss 0.09997902810573578\n",
      "Epoch  660\n",
      "------------\n",
      "Loss 0.29090067744255066\n",
      "Epoch  661\n",
      "------------\n",
      "Loss 0.6870265007019043\n",
      "Epoch  662\n",
      "------------\n",
      "Loss 2.5887410640716553\n",
      "Epoch  663\n",
      "------------\n",
      "Loss 0.31215280294418335\n",
      "Epoch  664\n",
      "------------\n",
      "Loss 0.36625757813453674\n",
      "Epoch  665\n",
      "------------\n",
      "Loss 0.5017002820968628\n",
      "Epoch  666\n",
      "------------\n",
      "Loss 0.8647210001945496\n",
      "Epoch  667\n",
      "------------\n",
      "Loss 0.12067224085330963\n",
      "Epoch  668\n",
      "------------\n",
      "Loss 0.12625882029533386\n",
      "Epoch  669\n",
      "------------\n",
      "Loss 0.12311142683029175\n",
      "Epoch  670\n",
      "------------\n",
      "Loss 0.31816160678863525\n",
      "Epoch  671\n",
      "------------\n",
      "Loss 0.13965803384780884\n",
      "Epoch  672\n",
      "------------\n",
      "Loss 0.3375188112258911\n",
      "Epoch  673\n",
      "------------\n",
      "Loss 0.3604963421821594\n",
      "Epoch  674\n",
      "------------\n",
      "Loss 0.06488244235515594\n",
      "Epoch  675\n",
      "------------\n",
      "Loss 0.20851168036460876\n",
      "Epoch  676\n",
      "------------\n",
      "Loss 0.36467844247817993\n",
      "Epoch  677\n",
      "------------\n",
      "Loss 0.09254681318998337\n",
      "Epoch  678\n",
      "------------\n",
      "Loss 0.13555030524730682\n",
      "Epoch  679\n",
      "------------\n",
      "Loss 0.11602209508419037\n",
      "Epoch  680\n",
      "------------\n",
      "Loss 0.12338144332170486\n",
      "Epoch  681\n",
      "------------\n",
      "Loss 1.4459508657455444\n",
      "Epoch  682\n",
      "------------\n",
      "Loss 0.2374374270439148\n",
      "Epoch  683\n",
      "------------\n",
      "Loss 0.07317684590816498\n",
      "Epoch  684\n",
      "------------\n",
      "Loss 0.13392490148544312\n",
      "Epoch  685\n",
      "------------\n",
      "Loss 0.10958407819271088\n",
      "Epoch  686\n",
      "------------\n",
      "Loss 0.3328622579574585\n",
      "Epoch  687\n",
      "------------\n",
      "Loss 2.009190082550049\n",
      "Epoch  688\n",
      "------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.34038880467414856\n",
      "Epoch  689\n",
      "------------\n",
      "Loss 0.18470895290374756\n",
      "Epoch  690\n",
      "------------\n",
      "Loss 0.1296493411064148\n",
      "Epoch  691\n",
      "------------\n",
      "Loss 0.3070521652698517\n",
      "Epoch  692\n",
      "------------\n",
      "Loss 0.27869608998298645\n",
      "Epoch  693\n",
      "------------\n",
      "Loss 0.19353854656219482\n",
      "Epoch  694\n",
      "------------\n",
      "Loss 0.5416972637176514\n",
      "Epoch  695\n",
      "------------\n",
      "Loss 0.4953286051750183\n",
      "Epoch  696\n",
      "------------\n",
      "Loss 0.07096809148788452\n",
      "Epoch  697\n",
      "------------\n",
      "Loss 0.28264519572257996\n",
      "Epoch  698\n",
      "------------\n",
      "Loss 0.27692288160324097\n",
      "Epoch  699\n",
      "------------\n",
      "Loss 0.17841637134552002\n",
      "Epoch  700\n",
      "------------\n",
      "Loss 0.16077634692192078\n",
      "Epoch  701\n",
      "------------\n",
      "Loss 0.07245775312185287\n",
      "Epoch  702\n",
      "------------\n",
      "Loss 0.07059796154499054\n",
      "Epoch  703\n",
      "------------\n",
      "Loss 0.27330559492111206\n",
      "Epoch  704\n",
      "------------\n",
      "Loss 0.24077308177947998\n",
      "Epoch  705\n",
      "------------\n",
      "Loss 0.09891823679208755\n",
      "Epoch  706\n",
      "------------\n",
      "Loss 4.188687324523926\n",
      "Epoch  707\n",
      "------------\n",
      "Loss 0.014553818851709366\n",
      "Epoch  708\n",
      "------------\n",
      "Loss 0.7615031003952026\n",
      "Epoch  709\n",
      "------------\n",
      "Loss 0.10154671967029572\n",
      "Epoch  710\n",
      "------------\n",
      "Loss 1.1606225967407227\n",
      "Epoch  711\n",
      "------------\n",
      "Loss 0.13729092478752136\n",
      "Epoch  712\n",
      "------------\n",
      "Loss 0.31262069940567017\n",
      "Epoch  713\n",
      "------------\n",
      "Loss 1.1208020448684692\n",
      "Epoch  714\n",
      "------------\n",
      "Loss 0.12970805168151855\n",
      "Epoch  715\n",
      "------------\n",
      "Loss 0.3517606854438782\n",
      "Epoch  716\n",
      "------------\n",
      "Loss 0.08031027019023895\n",
      "Epoch  717\n",
      "------------\n",
      "Loss 0.19933420419692993\n",
      "Epoch  718\n",
      "------------\n",
      "Loss 0.18531876802444458\n",
      "Epoch  719\n",
      "------------\n",
      "Loss 0.13295042514801025\n",
      "Epoch  720\n",
      "------------\n",
      "Loss 0.14645490050315857\n",
      "Epoch  721\n",
      "------------\n",
      "Loss 0.32853496074676514\n",
      "Epoch  722\n",
      "------------\n",
      "Loss 0.1285013109445572\n",
      "Epoch  723\n",
      "------------\n",
      "Loss 0.25155115127563477\n",
      "Epoch  724\n",
      "------------\n",
      "Loss 0.26028507947921753\n",
      "Epoch  725\n",
      "------------\n",
      "Loss 0.145338237285614\n",
      "Epoch  726\n",
      "------------\n",
      "Loss 0.20996445417404175\n",
      "Epoch  727\n",
      "------------\n",
      "Loss 0.1444467157125473\n",
      "Epoch  728\n",
      "------------\n",
      "Loss 0.11591432988643646\n",
      "Epoch  729\n",
      "------------\n",
      "Loss 0.23830091953277588\n",
      "Epoch  730\n",
      "------------\n",
      "Loss 0.39947155117988586\n",
      "Epoch  731\n",
      "------------\n",
      "Loss 0.13267163932323456\n",
      "Epoch  732\n",
      "------------\n",
      "Loss 1.0292267799377441\n",
      "Epoch  733\n",
      "------------\n",
      "Loss 0.194289430975914\n",
      "Epoch  734\n",
      "------------\n",
      "Loss 0.6233207583427429\n",
      "Epoch  735\n",
      "------------\n",
      "Loss 0.06800418347120285\n",
      "Epoch  736\n",
      "------------\n",
      "Loss 0.1869431436061859\n",
      "Epoch  737\n",
      "------------\n",
      "Loss 0.8266109824180603\n",
      "Epoch  738\n",
      "------------\n",
      "Loss 0.6114728450775146\n",
      "Epoch  739\n",
      "------------\n",
      "Loss 0.5759537220001221\n",
      "Epoch  740\n",
      "------------\n",
      "Loss 0.4350639283657074\n",
      "Epoch  741\n",
      "------------\n",
      "Loss 0.31296882033348083\n",
      "Epoch  742\n",
      "------------\n",
      "Loss 0.1864699125289917\n",
      "Epoch  743\n",
      "------------\n",
      "Loss 0.29006901383399963\n",
      "Epoch  744\n",
      "------------\n",
      "Loss 0.3689798414707184\n",
      "Epoch  745\n",
      "------------\n",
      "Loss 0.8876645565032959\n",
      "Epoch  746\n",
      "------------\n",
      "Loss 0.16334396600723267\n",
      "Epoch  747\n",
      "------------\n",
      "Loss 0.30228912830352783\n",
      "Epoch  748\n",
      "------------\n",
      "Loss 0.22601819038391113\n",
      "Epoch  749\n",
      "------------\n",
      "Loss 0.12152671813964844\n",
      "Epoch  750\n",
      "------------\n",
      "Loss 0.1907077580690384\n",
      "Epoch  751\n",
      "------------\n",
      "Loss 0.8651753664016724\n",
      "Epoch  752\n",
      "------------\n",
      "Loss 0.2414231300354004\n",
      "Epoch  753\n",
      "------------\n",
      "Loss 2.6861088275909424\n",
      "Epoch  754\n",
      "------------\n",
      "Loss 0.5403652787208557\n",
      "Epoch  755\n",
      "------------\n",
      "Loss 0.24346831440925598\n",
      "Epoch  756\n",
      "------------\n",
      "Loss 0.24484755098819733\n",
      "Epoch  757\n",
      "------------\n",
      "Loss 0.2464945912361145\n",
      "Epoch  758\n",
      "------------\n",
      "Loss 0.24700593948364258\n",
      "Epoch  759\n",
      "------------\n",
      "Loss 0.2938556671142578\n",
      "Epoch  760\n",
      "------------\n",
      "Loss 0.10069218277931213\n",
      "Epoch  761\n",
      "------------\n",
      "Loss 0.4907941222190857\n",
      "Epoch  762\n",
      "------------\n",
      "Loss 0.19362245500087738\n",
      "Epoch  763\n",
      "------------\n",
      "Loss 0.19632700085639954\n",
      "Epoch  764\n",
      "------------\n",
      "Loss 0.07895103842020035\n",
      "Epoch  765\n",
      "------------\n",
      "Loss 0.8058962821960449\n",
      "Epoch  766\n",
      "------------\n",
      "Loss 0.43898218870162964\n",
      "Epoch  767\n",
      "------------\n",
      "Loss 0.3485061526298523\n",
      "Epoch  768\n",
      "------------\n",
      "Loss 0.1012730598449707\n",
      "Epoch  769\n",
      "------------\n",
      "Loss 0.5938180088996887\n",
      "Epoch  770\n",
      "------------\n",
      "Loss 0.22502805292606354\n",
      "Epoch  771\n",
      "------------\n",
      "Loss 0.2796187102794647\n",
      "Epoch  772\n",
      "------------\n",
      "Loss 0.2771698236465454\n",
      "Epoch  773\n",
      "------------\n",
      "Loss 0.18905861675739288\n",
      "Epoch  774\n",
      "------------\n",
      "Loss 0.7482730150222778\n",
      "Epoch  775\n",
      "------------\n",
      "Loss 0.09415740519762039\n",
      "Epoch  776\n",
      "------------\n",
      "Loss 0.11399302631616592\n",
      "Epoch  777\n",
      "------------\n",
      "Loss 0.12362698465585709\n",
      "Epoch  778\n",
      "------------\n",
      "Loss 0.44225171208381653\n",
      "Epoch  779\n",
      "------------\n",
      "Loss 0.37395942211151123\n",
      "Epoch  780\n",
      "------------\n",
      "Loss 0.20479176938533783\n",
      "Epoch  781\n",
      "------------\n",
      "Loss 0.14160361886024475\n",
      "Epoch  782\n",
      "------------\n",
      "Loss 0.1645323485136032\n",
      "Epoch  783\n",
      "------------\n",
      "Loss 0.3527957499027252\n",
      "Epoch  784\n",
      "------------\n",
      "Loss 0.5659657120704651\n",
      "Epoch  785\n",
      "------------\n",
      "Loss 0.12398697435855865\n",
      "Epoch  786\n",
      "------------\n",
      "Loss 0.036590173840522766\n",
      "Epoch  787\n",
      "------------\n",
      "Loss 0.10154993832111359\n",
      "Epoch  788\n",
      "------------\n",
      "Loss 0.09894251823425293\n",
      "Epoch  789\n",
      "------------\n",
      "Loss 0.14789749681949615\n",
      "Epoch  790\n",
      "------------\n",
      "Loss 0.219331294298172\n",
      "Epoch  791\n",
      "------------\n",
      "Loss 2.3714559078216553\n",
      "Epoch  792\n",
      "------------\n",
      "Loss 0.666279673576355\n",
      "Epoch  793\n",
      "------------\n",
      "Loss 0.8755769729614258\n",
      "Epoch  794\n",
      "------------\n",
      "Loss 0.3388950824737549\n",
      "Epoch  795\n",
      "------------\n",
      "Loss 0.1422998011112213\n",
      "Epoch  796\n",
      "------------\n",
      "Loss 0.14178670942783356\n",
      "Epoch  797\n",
      "------------\n",
      "Loss 0.12991277873516083\n",
      "Epoch  798\n",
      "------------\n",
      "Loss 0.0834769606590271\n",
      "Epoch  799\n",
      "------------\n",
      "Loss 0.27000877261161804\n",
      "Epoch  800\n",
      "------------\n",
      "Loss 0.18453404307365417\n",
      "Epoch  801\n",
      "------------\n",
      "Loss 0.07733478397130966\n",
      "Epoch  802\n",
      "------------\n",
      "Loss 0.1514454185962677\n",
      "Epoch  803\n",
      "------------\n",
      "Loss 0.1821267306804657\n",
      "Epoch  804\n",
      "------------\n",
      "Loss 0.024896960705518723\n",
      "Epoch  805\n",
      "------------\n",
      "Loss 0.14918464422225952\n",
      "Epoch  806\n",
      "------------\n",
      "Loss 0.15105555951595306\n",
      "Epoch  807\n",
      "------------\n",
      "Loss 0.045832812786102295\n",
      "Epoch  808\n",
      "------------\n",
      "Loss 0.19324855506420135\n",
      "Epoch  809\n",
      "------------\n",
      "Loss 0.18879106640815735\n",
      "Epoch  810\n",
      "------------\n",
      "Loss 0.10189907252788544\n",
      "Epoch  811\n",
      "------------\n",
      "Loss 0.08953159302473068\n",
      "Epoch  812\n",
      "------------\n",
      "Loss 0.07301996648311615\n",
      "Epoch  813\n",
      "------------\n",
      "Loss 0.20830772817134857\n",
      "Epoch  814\n",
      "------------\n",
      "Loss 0.40467578172683716\n",
      "Epoch  815\n",
      "------------\n",
      "Loss 0.19828927516937256\n",
      "Epoch  816\n",
      "------------\n",
      "Loss 1.4568183422088623\n",
      "Epoch  817\n",
      "------------\n",
      "Loss 0.07624556124210358\n",
      "Epoch  818\n",
      "------------\n",
      "Loss 0.23612302541732788\n",
      "Epoch  819\n",
      "------------\n",
      "Loss 0.20670092105865479\n",
      "Epoch  820\n",
      "------------\n",
      "Loss 0.20985916256904602\n",
      "Epoch  821\n",
      "------------\n",
      "Loss 2.4326701164245605\n",
      "Epoch  822\n",
      "------------\n",
      "Loss 0.21589764952659607\n",
      "Epoch  823\n",
      "------------\n",
      "Loss 0.10819464921951294\n",
      "Epoch  824\n",
      "------------\n",
      "Loss 0.5301121473312378\n",
      "Epoch  825\n",
      "------------\n",
      "Loss 0.51407790184021\n",
      "Epoch  826\n",
      "------------\n",
      "Loss 0.1410333663225174\n",
      "Epoch  827\n",
      "------------\n",
      "Loss 0.11373432725667953\n",
      "Epoch  828\n",
      "------------\n",
      "Loss 0.16693425178527832\n",
      "Epoch  829\n",
      "------------\n",
      "Loss 0.3869985044002533\n",
      "Epoch  830\n",
      "------------\n",
      "Loss 0.28856128454208374\n",
      "Epoch  831\n",
      "------------\n",
      "Loss 0.2088574320077896\n",
      "Epoch  832\n",
      "------------\n",
      "Loss 0.04344385862350464\n",
      "Epoch  833\n",
      "------------\n",
      "Loss 0.13465213775634766\n",
      "Epoch  834\n",
      "------------\n",
      "Loss 0.17020133137702942\n",
      "Epoch  835\n",
      "------------\n",
      "Loss 0.16939496994018555\n",
      "Epoch  836\n",
      "------------\n",
      "Loss 0.15737643837928772\n",
      "Epoch  837\n",
      "------------\n",
      "Loss 0.17428679764270782\n",
      "Epoch  838\n",
      "------------\n",
      "Loss 0.2921465039253235\n",
      "Epoch  839\n",
      "------------\n",
      "Loss 0.23343804478645325\n",
      "Epoch  840\n",
      "------------\n",
      "Loss 0.14112040400505066\n",
      "Epoch  841\n",
      "------------\n",
      "Loss 0.26888373494148254\n",
      "Epoch  842\n",
      "------------\n",
      "Loss 0.14274808764457703\n",
      "Epoch  843\n",
      "------------\n",
      "Loss 0.3823210895061493\n",
      "Epoch  844\n",
      "------------\n",
      "Loss 0.1532200574874878\n",
      "Epoch  845\n",
      "------------\n",
      "Loss 2.4132299423217773\n",
      "Epoch  846\n",
      "------------\n",
      "Loss 0.8106248378753662\n",
      "Epoch  847\n",
      "------------\n",
      "Loss 0.3276737332344055\n",
      "Epoch  848\n",
      "------------\n",
      "Loss 0.09568910300731659\n",
      "Epoch  849\n",
      "------------\n",
      "Loss 0.05419238656759262\n",
      "Epoch  850\n",
      "------------\n",
      "Loss 0.22756023705005646\n",
      "Epoch  851\n",
      "------------\n",
      "Loss 0.1980728805065155\n",
      "Epoch  852\n",
      "------------\n",
      "Loss 0.37061530351638794\n",
      "Epoch  853\n",
      "------------\n",
      "Loss 0.2857675552368164\n",
      "Epoch  854\n",
      "------------\n",
      "Loss 0.6502652168273926\n",
      "Epoch  855\n",
      "------------\n",
      "Loss 0.05216410756111145\n",
      "Epoch  856\n",
      "------------\n",
      "Loss 0.1002940684556961\n",
      "Epoch  857\n",
      "------------\n",
      "Loss 0.20681974291801453\n",
      "Epoch  858\n",
      "------------\n",
      "Loss 0.5915752053260803\n",
      "Epoch  859\n",
      "------------\n",
      "Loss 0.05778282880783081\n",
      "Epoch  860\n",
      "------------\n",
      "Loss 0.2361791431903839\n",
      "Epoch  861\n",
      "------------\n",
      "Loss 0.1249975860118866\n",
      "Epoch  862\n",
      "------------\n",
      "Loss 0.06717377156019211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  863\n",
      "------------\n",
      "Loss 1.5326100587844849\n",
      "Epoch  864\n",
      "------------\n",
      "Loss 0.42358124256134033\n",
      "Epoch  865\n",
      "------------\n",
      "Loss 0.2351755052804947\n",
      "Epoch  866\n",
      "------------\n",
      "Loss 0.21224141120910645\n",
      "Epoch  867\n",
      "------------\n",
      "Loss 0.18080854415893555\n",
      "Epoch  868\n",
      "------------\n",
      "Loss 0.24248656630516052\n",
      "Epoch  869\n",
      "------------\n",
      "Loss 0.16771450638771057\n",
      "Epoch  870\n",
      "------------\n",
      "Loss 0.4545997083187103\n",
      "Epoch  871\n",
      "------------\n",
      "Loss 0.09158407896757126\n",
      "Epoch  872\n",
      "------------\n",
      "Loss 0.09368880093097687\n",
      "Epoch  873\n",
      "------------\n",
      "Loss 0.24783079326152802\n",
      "Epoch  874\n",
      "------------\n",
      "Loss 0.18188107013702393\n",
      "Epoch  875\n",
      "------------\n",
      "Loss 0.44844406843185425\n",
      "Epoch  876\n",
      "------------\n",
      "Loss 0.2608586549758911\n",
      "Epoch  877\n",
      "------------\n",
      "Loss 1.808258056640625\n",
      "Epoch  878\n",
      "------------\n",
      "Loss 0.2322089672088623\n",
      "Epoch  879\n",
      "------------\n",
      "Loss 0.189533531665802\n",
      "Epoch  880\n",
      "------------\n",
      "Loss 0.40743234753608704\n",
      "Epoch  881\n",
      "------------\n",
      "Loss 1.4013537168502808\n",
      "Epoch  882\n",
      "------------\n",
      "Loss 0.3161509931087494\n",
      "Epoch  883\n",
      "------------\n",
      "Loss 0.27732008695602417\n",
      "Epoch  884\n",
      "------------\n",
      "Loss 0.12491492927074432\n",
      "Epoch  885\n",
      "------------\n",
      "Loss 0.20785264670848846\n",
      "Epoch  886\n",
      "------------\n",
      "Loss 0.2572571635246277\n",
      "Epoch  887\n",
      "------------\n",
      "Loss 0.16839468479156494\n",
      "Epoch  888\n",
      "------------\n",
      "Loss 0.11904153227806091\n",
      "Epoch  889\n",
      "------------\n",
      "Loss 0.2549460530281067\n",
      "Epoch  890\n",
      "------------\n",
      "Loss 0.34371528029441833\n",
      "Epoch  891\n",
      "------------\n",
      "Loss 0.11601462960243225\n",
      "Epoch  892\n",
      "------------\n",
      "Loss 0.19070056080818176\n",
      "Epoch  893\n",
      "------------\n",
      "Loss 0.27436694502830505\n",
      "Epoch  894\n",
      "------------\n",
      "Loss 0.24901239573955536\n",
      "Epoch  895\n",
      "------------\n",
      "Loss 0.15937744081020355\n",
      "Epoch  896\n",
      "------------\n",
      "Loss 0.21110132336616516\n",
      "Epoch  897\n",
      "------------\n",
      "Loss 0.06480146944522858\n",
      "Epoch  898\n",
      "------------\n",
      "Loss 0.21085485816001892\n",
      "Epoch  899\n",
      "------------\n",
      "Loss 0.42145639657974243\n",
      "Epoch  900\n",
      "------------\n",
      "Loss 0.26678597927093506\n",
      "Epoch  901\n",
      "------------\n",
      "Loss 0.16436399519443512\n",
      "Epoch  902\n",
      "------------\n",
      "Loss 0.3457649350166321\n",
      "Epoch  903\n",
      "------------\n",
      "Loss 0.2028435468673706\n",
      "Epoch  904\n",
      "------------\n",
      "Loss 0.2647676467895508\n",
      "Epoch  905\n",
      "------------\n",
      "Loss 0.37419840693473816\n",
      "Epoch  906\n",
      "------------\n",
      "Loss 0.10103004425764084\n",
      "Epoch  907\n",
      "------------\n",
      "Loss 0.04717525467276573\n",
      "Epoch  908\n",
      "------------\n",
      "Loss 0.11896093189716339\n",
      "Epoch  909\n",
      "------------\n",
      "Loss 0.06802840530872345\n",
      "Epoch  910\n",
      "------------\n",
      "Loss 0.07696276903152466\n",
      "Epoch  911\n",
      "------------\n",
      "Loss 0.10920874774456024\n",
      "Epoch  912\n",
      "------------\n",
      "Loss 0.15122178196907043\n",
      "Epoch  913\n",
      "------------\n",
      "Loss 0.22610676288604736\n",
      "Epoch  914\n",
      "------------\n",
      "Loss 0.2934778332710266\n",
      "Epoch  915\n",
      "------------\n",
      "Loss 0.19353461265563965\n",
      "Epoch  916\n",
      "------------\n",
      "Loss 0.2769230902194977\n",
      "Epoch  917\n",
      "------------\n",
      "Loss 0.042772676795721054\n",
      "Epoch  918\n",
      "------------\n",
      "Loss 2.302278995513916\n",
      "Epoch  919\n",
      "------------\n",
      "Loss 0.18432924151420593\n",
      "Epoch  920\n",
      "------------\n",
      "Loss 0.13537225127220154\n",
      "Epoch  921\n",
      "------------\n",
      "Loss 0.1167483776807785\n",
      "Epoch  922\n",
      "------------\n",
      "Loss 0.133093923330307\n",
      "Epoch  923\n",
      "------------\n",
      "Loss 0.11507272720336914\n",
      "Epoch  924\n",
      "------------\n",
      "Loss 0.6161526441574097\n",
      "Epoch  925\n",
      "------------\n",
      "Loss 0.18924924731254578\n",
      "Epoch  926\n",
      "------------\n",
      "Loss 0.21735720336437225\n",
      "Epoch  927\n",
      "------------\n",
      "Loss 0.09225684404373169\n",
      "Epoch  928\n",
      "------------\n",
      "Loss 0.11672639101743698\n",
      "Epoch  929\n",
      "------------\n",
      "Loss 0.22419613599777222\n",
      "Epoch  930\n",
      "------------\n",
      "Loss 0.4634299874305725\n",
      "Epoch  931\n",
      "------------\n",
      "Loss 0.36388707160949707\n",
      "Epoch  932\n",
      "------------\n",
      "Loss 0.3803038001060486\n",
      "Epoch  933\n",
      "------------\n",
      "Loss 0.18127289414405823\n",
      "Epoch  934\n",
      "------------\n",
      "Loss 0.41634124517440796\n",
      "Epoch  935\n",
      "------------\n",
      "Loss 0.8878076076507568\n",
      "Epoch  936\n",
      "------------\n",
      "Loss 0.09094909578561783\n",
      "Epoch  937\n",
      "------------\n",
      "Loss 0.30382099747657776\n",
      "Epoch  938\n",
      "------------\n",
      "Loss 0.09256155788898468\n",
      "Epoch  939\n",
      "------------\n",
      "Loss 0.11085344105958939\n",
      "Epoch  940\n",
      "------------\n",
      "Loss 0.15936879813671112\n",
      "Epoch  941\n",
      "------------\n",
      "Loss 0.36649787425994873\n",
      "Epoch  942\n",
      "------------\n",
      "Loss 0.23635664582252502\n",
      "Epoch  943\n",
      "------------\n",
      "Loss 0.06741251051425934\n",
      "Epoch  944\n",
      "------------\n",
      "Loss 0.09602755308151245\n",
      "Epoch  945\n",
      "------------\n",
      "Loss 0.31427574157714844\n",
      "Epoch  946\n",
      "------------\n",
      "Loss 0.12589114904403687\n",
      "Epoch  947\n",
      "------------\n",
      "Loss 0.08626601845026016\n",
      "Epoch  948\n",
      "------------\n",
      "Loss 0.290979266166687\n",
      "Epoch  949\n",
      "------------\n",
      "Loss 0.34943073987960815\n",
      "Epoch  950\n",
      "------------\n",
      "Loss 0.15921485424041748\n",
      "Epoch  951\n",
      "------------\n",
      "Loss 0.22889238595962524\n",
      "Epoch  952\n",
      "------------\n",
      "Loss 0.11888477951288223\n",
      "Epoch  953\n",
      "------------\n",
      "Loss 0.33133915066719055\n",
      "Epoch  954\n",
      "------------\n",
      "Loss 0.3908126652240753\n",
      "Epoch  955\n",
      "------------\n",
      "Loss 0.28855159878730774\n",
      "Epoch  956\n",
      "------------\n",
      "Loss 1.9321588277816772\n",
      "Epoch  957\n",
      "------------\n",
      "Loss 0.6923255920410156\n",
      "Epoch  958\n",
      "------------\n",
      "Loss 0.15765348076820374\n",
      "Epoch  959\n",
      "------------\n",
      "Loss 0.1682349294424057\n",
      "Epoch  960\n",
      "------------\n",
      "Loss 0.11234953254461288\n",
      "Epoch  961\n",
      "------------\n",
      "Loss 0.20394039154052734\n",
      "Epoch  962\n",
      "------------\n",
      "Loss 0.09631146490573883\n",
      "Epoch  963\n",
      "------------\n",
      "Loss 0.1332424432039261\n",
      "Epoch  964\n",
      "------------\n",
      "Loss 0.2543233036994934\n",
      "Epoch  965\n",
      "------------\n",
      "Loss 0.0744381919503212\n",
      "Epoch  966\n",
      "------------\n",
      "Loss 0.724057674407959\n",
      "Epoch  967\n",
      "------------\n",
      "Loss 0.10710503160953522\n",
      "Epoch  968\n",
      "------------\n",
      "Loss 0.09157823026180267\n",
      "Epoch  969\n",
      "------------\n",
      "Loss 0.3968217968940735\n",
      "Epoch  970\n",
      "------------\n",
      "Loss 0.2617100477218628\n",
      "Epoch  971\n",
      "------------\n",
      "Loss 0.14746059477329254\n",
      "Epoch  972\n",
      "------------\n",
      "Loss 0.11742368340492249\n",
      "Epoch  973\n",
      "------------\n",
      "Loss 0.14969539642333984\n",
      "Epoch  974\n",
      "------------\n",
      "Loss 0.29818883538246155\n",
      "Epoch  975\n",
      "------------\n",
      "Loss 0.5524131059646606\n",
      "Epoch  976\n",
      "------------\n",
      "Loss 0.3483588695526123\n",
      "Epoch  977\n",
      "------------\n",
      "Loss 0.14253753423690796\n",
      "Epoch  978\n",
      "------------\n",
      "Loss 1.0294833183288574\n",
      "Epoch  979\n",
      "------------\n",
      "Loss 0.2205100655555725\n",
      "Epoch  980\n",
      "------------\n",
      "Loss 0.14860326051712036\n",
      "Epoch  981\n",
      "------------\n",
      "Loss 0.4044032692909241\n",
      "Epoch  982\n",
      "------------\n",
      "Loss 0.2229377031326294\n",
      "Epoch  983\n",
      "------------\n",
      "Loss 1.2290527820587158\n",
      "Epoch  984\n",
      "------------\n",
      "Loss 0.14559824764728546\n",
      "Epoch  985\n",
      "------------\n",
      "Loss 0.2394542098045349\n",
      "Epoch  986\n",
      "------------\n",
      "Loss 0.23930372297763824\n",
      "Epoch  987\n",
      "------------\n",
      "Loss 0.26676684617996216\n",
      "Epoch  988\n",
      "------------\n",
      "Loss 0.4873967468738556\n",
      "Epoch  989\n",
      "------------\n",
      "Loss 0.2568091154098511\n",
      "Epoch  990\n",
      "------------\n",
      "Loss 0.39931777119636536\n",
      "Epoch  991\n",
      "------------\n",
      "Loss 0.5287383794784546\n",
      "Epoch  992\n",
      "------------\n",
      "Loss 0.388409823179245\n",
      "Epoch  993\n",
      "------------\n",
      "Loss 0.2808135151863098\n",
      "Epoch  994\n",
      "------------\n",
      "Loss 0.934593141078949\n",
      "Epoch  995\n",
      "------------\n",
      "Loss 0.2479892373085022\n",
      "Epoch  996\n",
      "------------\n",
      "Loss 0.1136799231171608\n",
      "Epoch  997\n",
      "------------\n",
      "Loss 0.4056139588356018\n",
      "Epoch  998\n",
      "------------\n",
      "Loss 0.09539790451526642\n",
      "Epoch  999\n",
      "------------\n",
      "Loss 0.2844555377960205\n",
      "Epoch  1000\n",
      "------------\n",
      "Loss 0.09988293796777725\n",
      "Training Completed in 18.735613107681274 seconds!!!\n"
     ]
    }
   ],
   "source": [
    "epoch_list, loss_list = train_ddpg_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "856274bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = standard_replay_buffer[np.random.randint(standard_replay_buffer.shape[0], size=10), :]\n",
    "states = batch[:, 0:25]\n",
    "lps = choose_Action(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8975ae7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.982548713684082]\n",
      "[0.9938387274742126]\n",
      "[0.9893948435783386]\n",
      "[0.9998452067375183]\n",
      "[0.9778561592102051]\n",
      "[0.9833648204803467]\n",
      "[0.9986892342567444]\n",
      "[0.9892503023147583]\n",
      "[0.9813749194145203]\n",
      "[0.9946772456169128]\n"
     ]
    }
   ],
   "source": [
    "for lp in lps:\n",
    "    print(lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4672613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
